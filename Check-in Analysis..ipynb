{
  "metadata": {
    "name": "Check-in Analysis",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n# Query the check-in data\ncheckinDF \u003d spark.sql(\"SELECT checkin_dates FROM checkin\")\nfrom pyspark.sql.functions import year, count\n\n# Extract the year from the check-in date\ncheckinDF \u003d checkinDF.withColumn(\"checkin_year\", year(\"checkin_dates\"))\n\n# Count the check-ins per year\nyearlyCheckinCountDF \u003d checkinDF.groupBy(\"checkin_year\").agg(count(\"*\").alias(\"checkin_count\"))\n\n# Show the result\nz.show(yearlyCheckinCountDF)\n\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql.functions import hour\r\n\r\n# Extract the hour from the check-in date\r\ncheckinDF \u003d checkinDF.withColumn(\"checkin_hour\", hour(\"checkin_dates\"))\r\n\r\n# Count the check-ins per hour and order by check-in hour\r\nhourlyCheckinCountDF \u003d checkinDF.groupBy(\"checkin_hour\").count().orderBy(\"checkin_hour\")\r\n\r\n# Show the result\r\nz.show(hourlyCheckinCountDF)\r\n\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql import HiveContext\r\n \r\nhc \u003d HiveContext(sc)\r\nresult \u003d hc.sql(\"\"\"\r\n    SELECT b.city, COUNT(*) AS checkin_count\r\n    FROM checkin c\r\n    JOIN business b ON c.business_id \u003d b.business_id\r\n    GROUP BY b.city\r\n    ORDER BY checkin_count DESC\r\n\"\"\")\r\n \r\nz.show(result)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nfrom pyspark.sql import HiveContext\r\n\r\n# Create a HiveContext\r\nhc \u003d HiveContext(sc)\r\n\r\n# Execute SQL query to rank merchants based on check-in frequency\r\nmerchant_ranking \u003d hc.sql(\"\"\"\r\n    SELECT b.name AS merchant_name, COUNT(*) AS checkin_count\r\n    FROM checkin c\r\n    JOIN business b ON c.business_id \u003d b.business_id\r\n    GROUP BY b.name\r\n    ORDER BY checkin_count DESC\r\n\"\"\")\r\n\r\n# Show the result\r\nz.show(merchant_ranking)\r\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}