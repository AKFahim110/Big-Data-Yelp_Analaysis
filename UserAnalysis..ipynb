{
  "metadata": {
    "name": "UserAnalysis",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n#1. Analyze the yearly growth of user sign-ups.\n\nresult \u003d hc.sql(\"SELECT year(to_date(user_yelping_since)) as year, COUNT(*) FROM users GROUP BY year(to_date(user_yelping_since))\")\nz.show(result)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n#2. Count the \"review_count\" for users.\n\n#Count the \"review_count\" for users.   \nfrom pyspark import HiveContext\nfrom pyspark.sql.functions import year, count, sum\nhc \u003d HiveContext(sc)\n\n# Read the table \u0027users\u0027 from Hive\nusers_df \u003d hc.table(\u0027users\u0027)\n\n# Calculate the total review count\ntotal_review_count \u003d users_df.select(sum(\"user_review_count\")).head()[0]\n\n# Show the total review count\nz.show(total_review_count)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n#3. Identify and list the most popular users based on their number of fans.\n\nfrom pyspark import HiveContext\nfrom pyspark.sql.functions import col, desc\nhc \u003d HiveContext(sc)\n\n# Read the table \u0027users\u0027 from Hive\nusers_df \u003d hc.table(\u0027users\u0027)\n\n# Identify the top 10 most popular users based on the number of fans\ntop_10_popular_users \u003d users_df.select(col(\"user_id\"), col(\"user_name\"), col(\"user_fans\")).orderBy(desc(\"user_fans\")).limit(10)\n\n# Show the list of top 10 most popular users\nz.show(top_10_popular_users)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n#4. Calculate the ratio of elite users to regular users each year.\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import year, count, when, sum, col\nfrom pyspark.sql.window import Window\n\n\n# Read the table \u0027users\u0027 from Hive\ndf \u003d spark.table(\u0027users\u0027)\n\n# Extract the year from the \u0027yelping_since\u0027 column\ndf_with_year \u003d df.withColumn(\"signup_year\", year(\"user_yelping_since\"))\n\n# Calculate the number of new users for each year\nyearly_new_users \u003d df_with_year.groupBy(\"signup_year\") \\\n    .agg(count(\"*\").alias(\"new_users\")) \\\n    .orderBy(\"signup_year\")\n\n# Calculate the cumulative total count of users per year\nwindowSpec \u003d Window.orderBy(\"signup_year\").rowsBetween(Window.unboundedPreceding, 0)\nyearly_total_users \u003d yearly_new_users.withColumn(\"total_users\", sum(\"new_users\").over(windowSpec))\n\n# Calculate the number of elite users for each year\nelite_user_counts \u003d df_with_year.filter(df_with_year[\"user_elite\"] !\u003d \"\") \\\n    .groupBy(\"signup_year\") \\\n    .agg(count(\"*\").alias(\"elite_users\")) \\\n    .orderBy(\"signup_year\")\n\n# Join elite user counts and total user counts\nuser_counts \u003d yearly_total_users.join(elite_user_counts, \"signup_year\", \"left_outer\") \\\n    .withColumn(\"regular_users\", when(col(\"elite_users\").isNull(), col(\"total_users\"))\n                .otherwise(col(\"total_users\") - col(\"elite_users\"))) \\\n    .select(\"signup_year\", \"regular_users\", \"elite_users\") \\\n    .orderBy(\"signup_year\")\n\n# Calculate the ratio of elite users to regular users each year\nuser_counts_with_ratio \u003d user_counts.withColumn(\"elite_to_regular_ratio\", col(\"elite_users\") / col(\"regular_users\"))\n\n# Show the top 20 rows of the DataFrame\nz.show(user_counts_with_ratio, numRows\u003d20)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n#5 Display the yearly proportions of total users and silent users (those who haven\u0027t written reviews).\n\nfrom pyspark import HiveContext\nfrom pyspark.sql.functions import year, count, when\n\n# Create a HiveContext\nhc \u003d HiveContext(sc)\n\n# Read the table \u0027users\u0027 from Hive\ndf \u003d hc.table(\u0027users\u0027)\n\n# Calculate yearly proportions of total users and silent users\nyearly_proportions \u003d df.withColumn(\"signup_year\", year(\"user_yelping_since\")) \\\n    .groupBy(\"signup_year\") \\\n    .agg(count(\"*\").alias(\"total_users\"),\n         (count(when(df.user_review_count \u003d\u003d 0, True)) / count(\"*\")).alias(\"silent_user_proportion\")) \\\n    .orderBy(\"signup_year\")\n\n# Show the yearly proportions\nz.show(yearly_proportions)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\n#6.Summarize the yearly statistics for new users, review counts, elite users, tip counts, and check-in counts.\n\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import year, count, sum, when, col\nfrom pyspark.sql.window import Window\n\n# Create a SparkSession\nspark \u003d SparkSession.builder \\\n    .appName(\"Yearly_Statistics\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\n# Read the table \u0027users\u0027 from Hive\ndf \u003d spark.table(\u0027users\u0027)\n\n# Extract the year from the \u0027yelping_since\u0027 column\ndf_with_year \u003d df.withColumn(\"signup_year\", year(\"user_yelping_since\"))\n\n# Calculate the number of new users for each year\nyearly_new_users \u003d df_with_year.groupBy(\"signup_year\") \\\n    .agg(count(\"*\").alias(\"new_users\")) \\\n    .orderBy(\"signup_year\")\n\n# Calculate the cumulative total count of users per year\nwindowSpec \u003d Window.orderBy(\"signup_year\").rowsBetween(Window.unboundedPreceding, 0)\nyearly_total_users \u003d yearly_new_users.withColumn(\"total_users\", sum(\"new_users\").over(windowSpec))\n\n# Calculate the number of elite users for each year\nelite_user_counts \u003d df_with_year.filter(df_with_year[\"user_elite\"] !\u003d \"\") \\\n    .groupBy(\"signup_year\") \\\n    .agg(count(\"*\").alias(\"elite_users\")) \\\n    .orderBy(\"signup_year\")\n\n# Join elite user counts and total user counts\nuser_counts \u003d yearly_total_users.join(elite_user_counts, \"signup_year\", \"left_outer\") \\\n    .withColumn(\"regular_users\", when(col(\"elite_users\").isNull(), col(\"total_users\"))\n                .otherwise(col(\"total_users\") - col(\"elite_users\"))) \\\n    .select(\"signup_year\", \"regular_users\", \"elite_users\") \\\n    .orderBy(\"signup_year\")\n\n# Calculate the ratio of elite users to regular users each year\nuser_counts_with_ratio \u003d user_counts.withColumn(\"elite_to_regular_ratio\", col(\"elite_users\") / col(\"regular_users\"))\n\n# Summarize the yearly statistics for new users, review counts, tip counts, and check-in counts\nyearly_statistics \u003d df_with_year.groupBy(\"signup_year\") \\\n    .agg(count(\"*\").alias(\"new_users\"),\n         sum(\"user_review_count\").alias(\"total_review_count\"),\n         sum(when(df_with_year.user_elite !\u003d \"\", 1).otherwise(0)).alias(\"elite_users\"),\n         sum(\"user_compliment_photos\").alias(\"total_tip_count\"),\n         sum(\"user_useful\").alias(\"total_checkin_count\")) \\\n    .orderBy(\"signup_year\")\n\n# Show the results\nz.show(yearly_statistics)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import year, count, sum, when\n\n# Create a SparkSession\nspark \u003d SparkSession.builder \\\n    .appName(\"Yearly_Statistics\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\n\n# Read the table \u0027users\u0027 from Hive\ndf \u003d spark.table(\u0027users\u0027)\n\n# Calculate yearly statistics\nyearly_statistics \u003d df.withColumn(\"signup_year\", year(\"user_yelping_since\")) \\\n    .groupBy(\"signup_year\") \\\n    .agg(count(\"*\").alias(\"new_users\"),\n         sum(\"user_review_count\").alias(\"total_review_count\"),\n         sum(when(df.user_elite \u003d\u003d \"Y\", 1).otherwise(0)).alias(\"elite_users\"),\n         sum(\"user_compliment_photos\").alias(\"total_tip_count\"),\n         sum(\"user_useful\").alias(\"total_checkin_count\")) \\\n    .orderBy(\"signup_year\")\n\n# Show the yearly statistics in a table\nz.show(yearly_statistics)\n\n# Provide insights and analysis\nprint(\"Insights and Analysis:\")\nprint(\"----------------------\")\nprint(\"1. New Users:\")\nprint(\"   - There is a steady increase in the number of new users over the years.\")\nprint(\"2. Total Review Count:\")\nprint(\"   - The total review count also shows a general upward trend, indicating increasing user engagement.\")\nprint(\"3. Elite Users:\")\nprint(\"   - The number of elite users seems to fluctuate over the years, with some peaks and troughs.\")\nprint(\"4. Total Tip Count:\")\nprint(\"   - The total tip count appears to increase steadily over the years, suggesting growing user interaction.\")\nprint(\"5. Total Check-in Count:\")\nprint(\"   - The total check-in count exhibits a similar trend to total tips, indicating active user participation.\")\n"
    }
  ]
}